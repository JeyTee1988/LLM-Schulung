{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeyTee1988/LLM-Schulung/blob/main/TransformerVerstehen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wichtig**: Wenn Du dieses Notebook in Google Colab ausf√ºhrst, w√§hle zuerst unter \"Laufzeit > Laufzeittyp √§ndern\" eine GPU aus, um die Ausf√ºhrung zu beschleunigen."
      ],
      "metadata": {
        "id": "0B_oPwRRt5g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer verstehen\n",
        "\n",
        "Nun schauen wir in die Pipeline rein, um zu verstehen, wie Transformer funktionieren.\n",
        "\n",
        "Die Pipeline stellt unser gesamtes Language Model dar. Sie besteht bei Transformern aus einem Tokenizer und dem eigentlichen Neuronalen Netz."
      ],
      "metadata": {
        "id": "tPwmMOWNL4pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers einops accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8kxaMoccO5",
        "outputId": "39ba8aa7-3f20-407c-b394-fc918da29a2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "tokenizer = pipe.tokenizer\n",
        "model = pipe.model"
      ],
      "metadata": {
        "id": "dNlQzsi4Mlh-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "\n",
        "Der Tokenizer in einem (Large) Language Model (LLM) dient dazu, Text in kleinere Einheiten, sogenannte Tokens, zu zerlegen. Diese Tokens k√∂nnen einzelne W√∂rter, Phrasen oder sogar einzelne Buchstaben sein.\n",
        "\n",
        "Der Tokenizer ist wichtig, weil ein LLM wie ein neuronales Netzwerk arbeitet, das auf Zahlen, nicht auf W√∂rtern, basiert. Es kann nicht direkt Text verstehen oder interpretieren. Stattdessen muss es den Text in eine numerische Form umwandeln, die es verarbeiten kann.\n",
        "\n",
        "Dieser Prozess des Zerlegens und Umwandeln wird durch den Tokenizer durchgef√ºhrt. Er nimmt den urspr√ºnglichen Text, teilt ihn in Tokens und wandelt diese dann in Zahlen um, die das Modell verarbeiten kann.\n",
        "\n",
        "https://platform.openai.com/tokenizer\n"
      ],
      "metadata": {
        "id": "rIcp-u4CdZm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"We are happy to have you participate in our modest LLM workshop!\"\n",
        "tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9eFFJlca55Q",
        "outputId": "2adedba3-4003-4c29-a357-353a1bcf94c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We',\n",
              " 'ƒ†are',\n",
              " 'ƒ†happy',\n",
              " 'ƒ†to',\n",
              " 'ƒ†have',\n",
              " 'ƒ†you',\n",
              " 'ƒ†participate',\n",
              " 'ƒ†in',\n",
              " 'ƒ†our',\n",
              " 'ƒ†modest',\n",
              " 'ƒ†LL',\n",
              " 'M',\n",
              " 'ƒ†workshop',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "encoded_input.input_ids"
      ],
      "metadata": {
        "id": "ciBX-ajY7QKN",
        "outputId": "ca5ca397-1f23-4b9d-d96d-5817b4288792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1135,   389,  3772,   284,   423,   345,  8277,   287,   674, 12949,\n",
              "         27140,    44, 20243,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der Tokenizer enth√§lt ein Dictionary, welches jedem Token eine Zahl zuweist"
      ],
      "metadata": {
        "id": "odw5qLHEmMg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "first_20_items = {k: vocab[k] for k in list(vocab.keys())[:20]}\n",
        "first_20_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Pf725XkK-k",
        "outputId": "4d00ea69-bb03-46c7-bf3e-8bdf082c1c91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ƒ†372': 46633,\n",
              " 'ƒ†warns': 22145,\n",
              " 'ƒ†saturated': 24725,\n",
              " 'ƒ†Vo': 20687,\n",
              " 'Lind': 43410,\n",
              " 'ƒ†caregivers': 45044,\n",
              " 'ƒ†Aux': 47105,\n",
              " 'ƒ†clears': 37526,\n",
              " 'Guest': 42481,\n",
              " 'ƒ†timestamp': 41033,\n",
              " 'ƒ†Adamant': 42565,\n",
              " 'ƒ†culp': 21286,\n",
              " 'ƒ†reminis': 21484,\n",
              " 'ƒ†manufact': 4011,\n",
              " 'ƒ†dwarf': 24603,\n",
              " '727': 47760,\n",
              " 'el': 417,\n",
              " 'ƒ†until': 1566,\n",
              " 'ƒ†unexpected': 10059,\n",
              " 'ƒ†Stadium': 10499}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es gibt insgesamt 50257 Tokens in diesem Tokenizer."
      ],
      "metadata": {
        "id": "Shog8MajmdDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "2OKkMvuflu0w",
        "outputId": "01761d50-4fe4-4705-dfbd-db74eb490683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer-Modell\n",
        "\n",
        "Das Modell ist der eigentliche Transformer, der den encodierten Text entgegen nimmt und verarbeitet oder *transformiert* üòé."
      ],
      "metadata": {
        "id": "IhDN-6QhO9y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Die Ausgabe verstehen\n",
        "\n",
        "Statt die Pipeline als ganzes zu nutzen, k√∂nnen wir auch manuell die Ausgabe des Encoders durch unser Modell schleusen, um zu sehen, was es damit macht.\n",
        "\n",
        "Obwohl wir nur den fehlenden Text vervollst√§ndigen wollen, liefert unser Transformer tats√§chlich f√ºr **jedes** Token in unserem Input-Text eine Vorhersage f√ºr das n√§chste Token:"
      ],
      "metadata": {
        "id": "2FkwkXlyZpDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(**encoded_input)\n",
        "token_logits = output.logits\n",
        "\n",
        "# Get the predicted token ids\n",
        "predicted_token_ids = token_logits.argmax(dim=-1)\n",
        "predicted_token_ids"
      ],
      "metadata": {
        "id": "T2whQAHjotev",
        "outputId": "911931ea-cb50-4e0e-bb58-89e3d0a99adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  383,   407,   284,  5453,   262,   319,   287,   262,  7865, 18066,\n",
              "         15996,  1628,    13,   198]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the tokens to text\n",
        "predicted_text = [tokenizer.decode(t) for t in predicted_token_ids]\n",
        "\n",
        "for index, t in enumerate(predicted_token_ids[0]):\n",
        "  input_token = tokenizer.tokenize(text)[index]\n",
        "  predicted_next_token = tokenizer.decode(t)\n",
        "  print(input_token + \" => \" + predicted_next_token)\n"
      ],
      "metadata": {
        "id": "yQbzGTeipPTC",
        "outputId": "8e9f3107-4476-4dec-8e82-5f5602d59055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We =>  The\n",
            "ƒ†are =>  not\n",
            "ƒ†happy =>  to\n",
            "ƒ†to =>  announce\n",
            "ƒ†have =>  the\n",
            "ƒ†you =>  on\n",
            "ƒ†participate =>  in\n",
            "ƒ†in =>  the\n",
            "ƒ†our =>  upcoming\n",
            "ƒ†modest =>  fundraising\n",
            "ƒ†LL => VM\n",
            "M =>  project\n",
            "ƒ†workshop => .\n",
            "! => \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Das liegt daran, dass Transformer auf massiv parallele Verarbeitung und paralleles Training ausgelegt sind. Deswegen verarbeiten sie immer den gesamten Text parallel."
      ],
      "metadata": {
        "id": "Zj4vuGpN8OdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um eine gr√∂√üere Spanne von Texten erzeugen zu k√∂nnen, nutzen Transformer nicht immer die wahrscheinlichste Vorhersage (Stichwort **Temperatur**).\n",
        "\n",
        "Hier sind die f√ºnf wahrscheinlichsten Vorhersagen:"
      ],
      "metadata": {
        "id": "hIDPLbxQadRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert logits to probabilities\n",
        "token_probs = torch.nn.functional.softmax(token_logits, dim=-1)\n",
        "\n",
        "# Get the top 5 predicted token ids\n",
        "top_k = 5\n",
        "top_k_probs, top_k_indices = token_probs.topk(top_k, dim=-1)\n",
        "\n",
        "# Iterate over the tokens and print the top 5 predictions for each one\n",
        "for i in range(top_k_indices.shape[1]):\n",
        "    input_token = tokenizer.tokenize(text)[i]\n",
        "    print(f\"Input: {input_token}:\")\n",
        "    for j in range(top_k):\n",
        "        token_id = top_k_indices[0, i, j].item()\n",
        "        probability = top_k_probs[0, i, j].item()\n",
        "        output_token = tokenizer.decode([token_id])\n",
        "        print(f\"    Output: '{output_token}', probability: {probability:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmu3q6-qXwoh",
        "outputId": "1d7e664c-0043-4647-b7bf-10350539516f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: We:\n",
            "    Output: ' The', probability: 4.03%\n",
            "    Output: ' A', probability: 1.25%\n",
            "    Output: 'The', probability: 1.19%\n",
            "    Output: '\n",
            "', probability: 1.12%\n",
            "    Output: 'I', probability: 1.12%\n",
            "Input: ƒ†are:\n",
            "    Output: ' not', probability: 6.18%\n",
            "    Output: ' going', probability: 2.36%\n",
            "    Output: ' very', probability: 2.28%\n",
            "    Output: ' all', probability: 2.03%\n",
            "    Output: ' looking', probability: 1.96%\n",
            "Input: ƒ†happy:\n",
            "    Output: ' to', probability: 75.27%\n",
            "    Output: ' that', probability: 9.01%\n",
            "    Output: ' with', probability: 5.26%\n",
            "    Output: ' and', probability: 1.83%\n",
            "    Output: ' we', probability: 1.26%\n",
            "Input: ƒ†to:\n",
            "    Output: ' announce', probability: 55.91%\n",
            "    Output: ' be', probability: 4.09%\n",
            "    Output: ' have', probability: 3.21%\n",
            "    Output: ' share', probability: 3.20%\n",
            "    Output: ' welcome', probability: 2.78%\n",
            "Input: ƒ†have:\n",
            "    Output: ' the', probability: 10.51%\n",
            "    Output: ' been', probability: 6.17%\n",
            "    Output: ' a', probability: 5.33%\n",
            "    Output: ' you', probability: 3.68%\n",
            "    Output: ' this', probability: 2.67%\n",
            "Input: ƒ†you:\n",
            "    Output: ' on', probability: 10.74%\n",
            "    Output: ' all', probability: 8.79%\n",
            "    Output: ' in', probability: 8.00%\n",
            "    Output: ' with', probability: 7.43%\n",
            "    Output: ' back', probability: 5.68%\n",
            "Input: ƒ†participate:\n",
            "    Output: ' in', probability: 76.62%\n",
            "    Output: '.', probability: 5.35%\n",
            "    Output: ' and', probability: 4.71%\n",
            "    Output: '!', probability: 2.80%\n",
            "    Output: ',', probability: 2.03%\n",
            "Input: ƒ†in:\n",
            "    Output: ' the', probability: 30.19%\n",
            "    Output: ' this', probability: 21.03%\n",
            "    Output: ' our', probability: 16.91%\n",
            "    Output: ' a', probability: 8.07%\n",
            "    Output: ' an', probability: 2.01%\n",
            "Input: ƒ†our:\n",
            "    Output: ' upcoming', probability: 2.22%\n",
            "    Output: ' new', probability: 1.80%\n",
            "    Output: ' community', probability: 1.61%\n",
            "    Output: ' annual', probability: 1.60%\n",
            "    Output: ' project', probability: 1.51%\n",
            "Input: ƒ†modest:\n",
            "    Output: ' fundraising', probability: 3.39%\n",
            "    Output: ',', probability: 3.16%\n",
            "    Output: 'ly', probability: 2.12%\n",
            "    Output: ' and', probability: 2.08%\n",
            "    Output: ' community', probability: 1.38%\n",
            "Input: ƒ†LL:\n",
            "    Output: 'VM', probability: 10.40%\n",
            "    Output: 'G', probability: 2.89%\n",
            "    Output: 'AP', probability: 2.36%\n",
            "    Output: 'F', probability: 1.90%\n",
            "    Output: 'K', probability: 1.77%\n",
            "Input: M:\n",
            "    Output: ' project', probability: 7.36%\n",
            "    Output: ' program', probability: 2.70%\n",
            "    Output: '-', probability: 1.91%\n",
            "    Output: ' event', probability: 1.57%\n",
            "    Output: ' and', probability: 1.44%\n",
            "Input: ƒ†workshop:\n",
            "    Output: '.', probability: 23.24%\n",
            "    Output: ',', probability: 10.71%\n",
            "    Output: ' in', probability: 7.96%\n",
            "    Output: ' on', probability: 7.20%\n",
            "    Output: ' and', probability: 6.62%\n",
            "Input: !:\n",
            "    Output: '\n",
            "', probability: 40.09%\n",
            "    Output: ' We', probability: 6.57%\n",
            "    Output: '<|endoftext|>', probability: 6.24%\n",
            "    Output: ' You', probability: 2.44%\n",
            "    Output: ' Please', probability: 2.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Die Architektur verstehen\n"
      ],
      "metadata": {
        "id": "GCmBb-xMh1Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Laden des vortrainierten Modells und des zugeh√∂rigen Tokenizers\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2', output_hidden_states=True)\n",
        "\n",
        "# GPU nutzen wenn verf√ºgar\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device).eval()\n",
        "\n",
        "text = 'Das ist ein Beispieltext f√ºr die Demonstration.'\n",
        "\n",
        "tokens = tokenizer.tokenize(text)\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# Verfolgen der Ver√§nderungen in den latenten Zust√§nden und Best√§tigen der konstanten Dimension.\n",
        "# Dazu f√ºhren wir die Eingabe durch das gesamte Modell und drucken die Gr√∂√üe der Ausgabe nach jedem Block\n",
        "input_tensor = torch.tensor([input_ids], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Durchf√ºhren einer Vorw√§rtsdurchlaufe durch das Modell\n",
        "    outputs = model(input_tensor)\n",
        "    # Die Ausgabe ist ein Tuple, das die Endausgabe und eine Liste der Zwischenausgaben enth√§lt\n",
        "    final_output, hidden_states = outputs.last_hidden_state, outputs.hidden_states\n",
        "    # Drucken Sie die Gr√∂√üe der Endausgabe und jeder Zwischenausgabe\n",
        "    print(f\"Gr√∂√üe der Endausgabe:\\n\\t{final_output.size()}\\n\")\n",
        "    print(f\"Endausgabe:\\n\\t{final_output}\\n\")\n",
        "    for i, hidden_state in enumerate(hidden_states):\n",
        "        print(f\"Gr√∂√üe der latenten Zust√§nde nach Block {i+1}:\\n\\t{hidden_state.size()}\\n\")\n",
        "        print(f\"Latente Zust√§nde nach Block {i+1}:\\n\\t{hidden_state}\\n\\n\")"
      ],
      "metadata": {
        "id": "4ozdyQmdiNS7",
        "outputId": "c69ef7de-8f2f-47a0-dbf4-90a544c79853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gr√∂√üe der Endausgabe:\n",
            "\ttorch.Size([1, 1, 16, 768])\n",
            "\n",
            "Endausgabe:\n",
            "\ttensor([[[[-0.1805, -0.1602, -0.2445,  ..., -0.1593,  0.0039, -0.0136],\n",
            "          [-0.3021, -0.3064, -0.4753,  ...,  0.0716, -0.1752,  0.2778],\n",
            "          [-0.6312, -0.3724, -0.7612,  ...,  0.3610, -0.1038,  0.0860],\n",
            "          ...,\n",
            "          [ 0.6071, -0.1206, -0.9526,  ..., -0.4354,  0.0310, -0.5339],\n",
            "          [ 0.0030, -0.4362, -0.2058,  ..., -0.1486, -0.3879, -0.3260],\n",
            "          [ 0.0698, -0.4597, -0.5089,  ..., -0.2768, -0.2152, -0.0472]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 1:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 1:\n",
            "\ttensor([[[ 0.0911, -0.1488,  0.1890,  ..., -0.0553,  0.1373, -0.0367],\n",
            "         [-0.0502, -0.2643, -0.0026,  ...,  0.1705, -0.0574, -0.0334],\n",
            "         [-0.0055, -0.0747,  0.1101,  ...,  0.1342, -0.0187, -0.0468],\n",
            "         ...,\n",
            "         [-0.0501,  0.0583,  0.4026,  ..., -0.0276, -0.2199, -0.0523],\n",
            "         [-0.0544,  0.0188,  0.1011,  ..., -0.0354, -0.1995, -0.0073],\n",
            "         [ 0.0488,  0.0092,  0.1127,  ..., -0.0773,  0.0460,  0.0949]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 2:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 2:\n",
            "\ttensor([[[-8.6780e-01, -1.6939e+00,  8.1993e-01,  ..., -1.4451e+00,\n",
            "          -3.3099e-01,  1.2529e+00],\n",
            "         [-2.3711e+00, -8.9153e-02, -4.1907e-01,  ...,  1.0834e-01,\n",
            "          -2.9978e-02,  6.5335e-01],\n",
            "         [-1.4507e+00, -6.1375e-01, -8.5436e-01,  ...,  6.6315e-01,\n",
            "           1.7717e-04,  8.3909e-01],\n",
            "         ...,\n",
            "         [ 3.0882e+00,  1.7970e-01, -7.9437e-01,  ..., -5.6782e-01,\n",
            "          -1.4546e+00, -9.5938e-01],\n",
            "         [-3.3333e-01, -2.1266e-01,  4.1606e-02,  ...,  4.4749e-01,\n",
            "          -6.7261e-01, -9.5239e-01],\n",
            "         [ 1.1582e+00,  7.7274e-03, -5.7502e-01,  ..., -3.3415e-02,\n",
            "          -1.7869e-01,  1.4895e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 3:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 3:\n",
            "\ttensor([[[-0.9689, -1.9875,  0.9241,  ..., -1.2349,  0.6611,  0.6452],\n",
            "         [-1.6984,  0.1247, -0.4265,  ...,  0.0724,  0.2886,  0.4197],\n",
            "         [-1.0819, -0.7272, -1.4148,  ...,  1.2566,  0.3688,  1.2374],\n",
            "         ...,\n",
            "         [ 3.9381,  0.5510, -1.8351,  ..., -0.4392, -1.3800, -0.3870],\n",
            "         [-0.8068,  0.2660, -0.5286,  ...,  0.3036, -0.7980, -1.0378],\n",
            "         [ 1.6444, -0.4830, -0.9405,  ..., -0.3132,  0.1983,  0.5502]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 4:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 4:\n",
            "\ttensor([[[-0.7086, -2.2935,  0.5609,  ..., -1.2166,  0.8711,  0.5059],\n",
            "         [-1.4906, -0.4384, -0.7218,  ..., -0.5867,  1.3711,  0.4464],\n",
            "         [-1.4419, -0.9732, -2.0607,  ...,  1.2049,  0.1657,  1.0424],\n",
            "         ...,\n",
            "         [ 4.4492,  0.0394, -1.8546,  ..., -1.0592, -1.3634, -0.3636],\n",
            "         [-1.3139,  0.0855, -0.8313,  ...,  0.1707,  0.2583, -0.8920],\n",
            "         [ 1.9362, -0.8187, -1.0610,  ..., -0.1899,  0.2908,  0.7416]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 5:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 5:\n",
            "\ttensor([[[-6.4127e-01, -2.2873e+00,  6.1733e-01,  ..., -1.1654e+00,\n",
            "           8.6678e-01,  3.6842e-01],\n",
            "         [-2.1190e+00, -6.8900e-01, -3.3142e-01,  ...,  7.1661e-01,\n",
            "           3.0818e-01,  4.4499e-01],\n",
            "         [-1.7893e+00, -4.3250e-01, -1.9582e+00,  ...,  1.2738e+00,\n",
            "          -5.9711e-01,  1.3264e+00],\n",
            "         ...,\n",
            "         [ 4.8933e+00, -2.4944e-01, -1.8925e+00,  ..., -1.7886e+00,\n",
            "          -1.7745e+00,  2.0310e-01],\n",
            "         [-9.0010e-01,  7.9144e-01, -1.5351e+00,  ...,  1.4976e-01,\n",
            "          -2.5617e-03, -9.2712e-01],\n",
            "         [ 1.7856e+00, -1.0759e+00, -9.3823e-01,  ..., -2.0255e-01,\n",
            "          -1.8251e-01,  5.9054e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 6:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 6:\n",
            "\ttensor([[[-0.8285, -2.3596,  0.5320,  ..., -1.3341,  0.7238,  0.3699],\n",
            "         [-1.1233, -1.4394, -0.5654,  ...,  0.6341,  0.1042,  0.2412],\n",
            "         [-1.7185, -0.3660, -1.9395,  ...,  1.1227, -1.4451,  1.7288],\n",
            "         ...,\n",
            "         [ 5.5515,  0.2181, -2.3139,  ..., -2.1099, -2.3544,  0.3981],\n",
            "         [-0.9635,  1.3844, -2.1596,  ..., -0.8610, -0.4416, -0.6148],\n",
            "         [ 1.8560, -1.6745, -1.2009,  ..., -0.4101, -0.5796,  0.3958]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 7:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 7:\n",
            "\ttensor([[[-0.8537, -2.4543,  0.5723,  ..., -1.4362,  0.6389,  0.3736],\n",
            "         [-1.6854, -2.0881, -0.8161,  ..., -0.4309, -1.3993,  1.0281],\n",
            "         [-1.8814,  0.1707, -2.2969,  ...,  0.3322, -2.0702,  1.4498],\n",
            "         ...,\n",
            "         [ 5.7863,  0.1437, -2.4282,  ..., -2.7702, -1.8702, -0.2987],\n",
            "         [-1.0866,  1.6824, -2.5665,  ..., -0.7798,  0.2325, -0.4299],\n",
            "         [ 1.6239, -1.6974, -1.2744,  ..., -0.0482, -0.0436,  0.8880]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 8:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 8:\n",
            "\ttensor([[[-0.9446, -2.4644,  0.6284,  ..., -1.5110,  0.6196,  0.3989],\n",
            "         [-1.7603, -1.7282, -1.5534,  ...,  0.7757, -2.5871,  1.3991],\n",
            "         [-1.6237,  0.1183, -2.4290,  ...,  0.2173, -2.0877,  2.2281],\n",
            "         ...,\n",
            "         [ 6.6249,  0.5627, -3.2050,  ..., -2.7895, -2.0410, -0.5208],\n",
            "         [-1.5364,  0.4954, -3.0861,  ..., -0.3838, -0.1180, -0.0535],\n",
            "         [ 0.5571, -3.3804, -2.6739,  ...,  0.4513,  0.5364,  1.4572]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 9:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 9:\n",
            "\ttensor([[[-0.9980, -2.3843,  0.5015,  ..., -1.4533,  0.5272,  0.2545],\n",
            "         [-1.9110, -1.0399, -0.8994,  ...,  1.6302, -2.6736,  2.1934],\n",
            "         [-1.8689, -0.3377, -2.4041,  ...,  1.0703, -2.3965,  2.0800],\n",
            "         ...,\n",
            "         [ 7.4649,  0.7959, -1.3910,  ..., -2.2043, -0.7415, -1.6840],\n",
            "         [ 0.2641,  0.2894, -2.1732,  ...,  1.1806,  0.1958, -1.1574],\n",
            "         [ 1.6692, -3.3584, -2.8830,  ...,  0.1992,  0.8593,  1.8930]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 10:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 10:\n",
            "\ttensor([[[-0.9850, -2.3361,  0.4464,  ..., -1.3621,  0.4881,  0.1393],\n",
            "         [-0.9442, -1.0247, -2.2042,  ...,  1.0314, -1.3090,  2.7587],\n",
            "         [-3.2372, -1.3802, -2.5874,  ...,  2.0381, -1.4779,  1.9904],\n",
            "         ...,\n",
            "         [ 7.6763,  3.1915, -3.4594,  ..., -3.2668,  1.6244, -3.6151],\n",
            "         [ 0.5654,  1.2110, -3.2167,  ...,  0.2370,  1.0944, -2.7497],\n",
            "         [ 1.8687, -3.0614, -4.6514,  ...,  0.8904,  2.6225,  1.1862]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 11:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 11:\n",
            "\ttensor([[[-1.0544, -2.2440,  0.1360,  ..., -1.3183,  0.6060, -0.1071],\n",
            "         [-2.1870, -1.6601, -3.0674,  ...,  0.8746, -1.1006,  2.6336],\n",
            "         [-4.8073, -2.8698, -4.2580,  ...,  3.7331, -0.9701,  1.4990],\n",
            "         ...,\n",
            "         [ 5.7784,  1.6183, -6.0714,  ..., -4.6667,  2.0194, -6.0991],\n",
            "         [-2.2743,  1.4888, -3.1535,  ..., -1.7445,  0.5930, -5.7910],\n",
            "         [-0.1192, -2.3250, -6.6739,  ..., -2.7141,  1.6907, -0.8877]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 12:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 12:\n",
            "\ttensor([[[-1.1886e+00, -2.1410e+00, -1.6110e-01,  ..., -1.3091e+00,\n",
            "           8.4109e-01, -3.4720e-01],\n",
            "         [-1.9333e+00, -3.0579e+00, -3.1960e+00,  ...,  9.9296e-01,\n",
            "          -6.6876e-01,  2.4818e+00],\n",
            "         [-6.3601e+00, -4.4979e+00, -6.2238e+00,  ...,  4.8597e+00,\n",
            "          -6.3024e-01,  1.1468e+00],\n",
            "         ...,\n",
            "         [ 5.2111e+00,  1.6977e+00, -5.5917e+00,  ..., -3.9830e+00,\n",
            "           2.4351e+00, -6.2948e+00],\n",
            "         [-8.8515e-01, -2.3185e-03, -1.1801e+00,  ..., -1.6234e+00,\n",
            "          -3.0710e+00, -6.2010e+00],\n",
            "         [ 4.0168e-01, -1.0885e+00, -5.5801e+00,  ..., -2.0260e+00,\n",
            "          -1.7729e+00, -4.0947e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Gr√∂√üe der latenten Zust√§nde nach Block 13:\n",
            "\ttorch.Size([1, 1, 16, 768])\n",
            "\n",
            "Latente Zust√§nde nach Block 13:\n",
            "\ttensor([[[[-0.1805, -0.1602, -0.2445,  ..., -0.1593,  0.0039, -0.0136],\n",
            "          [-0.3021, -0.3064, -0.4753,  ...,  0.0716, -0.1752,  0.2778],\n",
            "          [-0.6312, -0.3724, -0.7612,  ...,  0.3610, -0.1038,  0.0860],\n",
            "          ...,\n",
            "          [ 0.6071, -0.1206, -0.9526,  ..., -0.4354,  0.0310, -0.5339],\n",
            "          [ 0.0030, -0.4362, -0.2058,  ..., -0.1486, -0.3879, -0.3260],\n",
            "          [ 0.0698, -0.4597, -0.5089,  ..., -0.2768, -0.2152, -0.0472]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}