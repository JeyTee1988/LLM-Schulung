{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeyTee1988/LLM-Schulung/blob/main/TransformerVerstehen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wichtig**: Wenn Du dieses Notebook in Google Colab ausführst, wähle zuerst unter \"Laufzeit > Laufzeittyp ändern\" eine GPU aus, um die Ausführung zu beschleunigen."
      ],
      "metadata": {
        "id": "0B_oPwRRt5g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer verstehen\n",
        "\n",
        "Nun schauen wir in die Pipeline rein, um zu verstehen, wie Transformer funktionieren.\n",
        "\n",
        "Die Pipeline stellt unser gesamtes Language Model dar. Sie besteht bei Transformern aus einem Tokenizer und dem eigentlichen Neuronalen Netz."
      ],
      "metadata": {
        "id": "tPwmMOWNL4pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers einops accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8kxaMoccO5",
        "outputId": "39ba8aa7-3f20-407c-b394-fc918da29a2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "tokenizer = pipe.tokenizer\n",
        "model = pipe.model"
      ],
      "metadata": {
        "id": "dNlQzsi4Mlh-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "\n",
        "Der Tokenizer in einem (Large) Language Model (LLM) dient dazu, Text in kleinere Einheiten, sogenannte Tokens, zu zerlegen. Diese Tokens können einzelne Wörter, Phrasen oder sogar einzelne Buchstaben sein.\n",
        "\n",
        "Der Tokenizer ist wichtig, weil ein LLM wie ein neuronales Netzwerk arbeitet, das auf Zahlen, nicht auf Wörtern, basiert. Es kann nicht direkt Text verstehen oder interpretieren. Stattdessen muss es den Text in eine numerische Form umwandeln, die es verarbeiten kann.\n",
        "\n",
        "Dieser Prozess des Zerlegens und Umwandeln wird durch den Tokenizer durchgeführt. Er nimmt den ursprünglichen Text, teilt ihn in Tokens und wandelt diese dann in Zahlen um, die das Modell verarbeiten kann.\n",
        "\n",
        "https://platform.openai.com/tokenizer\n"
      ],
      "metadata": {
        "id": "rIcp-u4CdZm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"We are happy to have you participate in our modest LLM workshop!\"\n",
        "tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9eFFJlca55Q",
        "outputId": "2adedba3-4003-4c29-a357-353a1bcf94c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We',\n",
              " 'Ġare',\n",
              " 'Ġhappy',\n",
              " 'Ġto',\n",
              " 'Ġhave',\n",
              " 'Ġyou',\n",
              " 'Ġparticipate',\n",
              " 'Ġin',\n",
              " 'Ġour',\n",
              " 'Ġmodest',\n",
              " 'ĠLL',\n",
              " 'M',\n",
              " 'Ġworkshop',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "encoded_input.input_ids"
      ],
      "metadata": {
        "id": "ciBX-ajY7QKN",
        "outputId": "ca5ca397-1f23-4b9d-d96d-5817b4288792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1135,   389,  3772,   284,   423,   345,  8277,   287,   674, 12949,\n",
              "         27140,    44, 20243,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der Tokenizer enthält ein Dictionary, welches jedem Token eine Zahl zuweist"
      ],
      "metadata": {
        "id": "odw5qLHEmMg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "first_20_items = {k: vocab[k] for k in list(vocab.keys())[:20]}\n",
        "first_20_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Pf725XkK-k",
        "outputId": "4d00ea69-bb03-46c7-bf3e-8bdf082c1c91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ġ372': 46633,\n",
              " 'Ġwarns': 22145,\n",
              " 'Ġsaturated': 24725,\n",
              " 'ĠVo': 20687,\n",
              " 'Lind': 43410,\n",
              " 'Ġcaregivers': 45044,\n",
              " 'ĠAux': 47105,\n",
              " 'Ġclears': 37526,\n",
              " 'Guest': 42481,\n",
              " 'Ġtimestamp': 41033,\n",
              " 'ĠAdamant': 42565,\n",
              " 'Ġculp': 21286,\n",
              " 'Ġreminis': 21484,\n",
              " 'Ġmanufact': 4011,\n",
              " 'Ġdwarf': 24603,\n",
              " '727': 47760,\n",
              " 'el': 417,\n",
              " 'Ġuntil': 1566,\n",
              " 'Ġunexpected': 10059,\n",
              " 'ĠStadium': 10499}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es gibt insgesamt 50257 Tokens in diesem Tokenizer."
      ],
      "metadata": {
        "id": "Shog8MajmdDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "2OKkMvuflu0w",
        "outputId": "01761d50-4fe4-4705-dfbd-db74eb490683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer-Modell\n",
        "\n",
        "Das Modell ist der eigentliche Transformer, der den encodierten Text entgegen nimmt und verarbeitet oder *transformiert* 😎."
      ],
      "metadata": {
        "id": "IhDN-6QhO9y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Die Ausgabe verstehen\n",
        "\n",
        "Statt die Pipeline als ganzes zu nutzen, können wir auch manuell die Ausgabe des Encoders durch unser Modell schleusen, um zu sehen, was es damit macht.\n",
        "\n",
        "Obwohl wir nur den fehlenden Text vervollständigen wollen, liefert unser Transformer tatsächlich für **jedes** Token in unserem Input-Text eine Vorhersage für das nächste Token:"
      ],
      "metadata": {
        "id": "2FkwkXlyZpDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(**encoded_input)\n",
        "token_logits = output.logits\n",
        "\n",
        "# Get the predicted token ids\n",
        "predicted_token_ids = token_logits.argmax(dim=-1)\n",
        "predicted_token_ids"
      ],
      "metadata": {
        "id": "T2whQAHjotev",
        "outputId": "911931ea-cb50-4e0e-bb58-89e3d0a99adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  383,   407,   284,  5453,   262,   319,   287,   262,  7865, 18066,\n",
              "         15996,  1628,    13,   198]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the tokens to text\n",
        "predicted_text = [tokenizer.decode(t) for t in predicted_token_ids]\n",
        "\n",
        "for index, t in enumerate(predicted_token_ids[0]):\n",
        "  input_token = tokenizer.tokenize(text)[index]\n",
        "  predicted_next_token = tokenizer.decode(t)\n",
        "  print(input_token + \" => \" + predicted_next_token)\n"
      ],
      "metadata": {
        "id": "yQbzGTeipPTC",
        "outputId": "8e9f3107-4476-4dec-8e82-5f5602d59055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We =>  The\n",
            "Ġare =>  not\n",
            "Ġhappy =>  to\n",
            "Ġto =>  announce\n",
            "Ġhave =>  the\n",
            "Ġyou =>  on\n",
            "Ġparticipate =>  in\n",
            "Ġin =>  the\n",
            "Ġour =>  upcoming\n",
            "Ġmodest =>  fundraising\n",
            "ĠLL => VM\n",
            "M =>  project\n",
            "Ġworkshop => .\n",
            "! => \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Das liegt daran, dass Transformer auf massiv parallele Verarbeitung und paralleles Training ausgelegt sind. Deswegen verarbeiten sie immer den gesamten Text parallel."
      ],
      "metadata": {
        "id": "Zj4vuGpN8OdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um eine größere Spanne von Texten erzeugen zu können, nutzen Transformer nicht immer die wahrscheinlichste Vorhersage (Stichwort **Temperatur**).\n",
        "\n",
        "Hier sind die fünf wahrscheinlichsten Vorhersagen:"
      ],
      "metadata": {
        "id": "hIDPLbxQadRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert logits to probabilities\n",
        "token_probs = torch.nn.functional.softmax(token_logits, dim=-1)\n",
        "\n",
        "# Get the top 5 predicted token ids\n",
        "top_k = 5\n",
        "top_k_probs, top_k_indices = token_probs.topk(top_k, dim=-1)\n",
        "\n",
        "# Iterate over the tokens and print the top 5 predictions for each one\n",
        "for i in range(top_k_indices.shape[1]):\n",
        "    input_token = tokenizer.tokenize(text)[i]\n",
        "    print(f\"Input: {input_token}:\")\n",
        "    for j in range(top_k):\n",
        "        token_id = top_k_indices[0, i, j].item()\n",
        "        probability = top_k_probs[0, i, j].item()\n",
        "        output_token = tokenizer.decode([token_id])\n",
        "        print(f\"    Output: '{output_token}', probability: {probability:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmu3q6-qXwoh",
        "outputId": "1d7e664c-0043-4647-b7bf-10350539516f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: We:\n",
            "    Output: ' The', probability: 4.03%\n",
            "    Output: ' A', probability: 1.25%\n",
            "    Output: 'The', probability: 1.19%\n",
            "    Output: '\n",
            "', probability: 1.12%\n",
            "    Output: 'I', probability: 1.12%\n",
            "Input: Ġare:\n",
            "    Output: ' not', probability: 6.18%\n",
            "    Output: ' going', probability: 2.36%\n",
            "    Output: ' very', probability: 2.28%\n",
            "    Output: ' all', probability: 2.03%\n",
            "    Output: ' looking', probability: 1.96%\n",
            "Input: Ġhappy:\n",
            "    Output: ' to', probability: 75.27%\n",
            "    Output: ' that', probability: 9.01%\n",
            "    Output: ' with', probability: 5.26%\n",
            "    Output: ' and', probability: 1.83%\n",
            "    Output: ' we', probability: 1.26%\n",
            "Input: Ġto:\n",
            "    Output: ' announce', probability: 55.91%\n",
            "    Output: ' be', probability: 4.09%\n",
            "    Output: ' have', probability: 3.21%\n",
            "    Output: ' share', probability: 3.20%\n",
            "    Output: ' welcome', probability: 2.78%\n",
            "Input: Ġhave:\n",
            "    Output: ' the', probability: 10.51%\n",
            "    Output: ' been', probability: 6.17%\n",
            "    Output: ' a', probability: 5.33%\n",
            "    Output: ' you', probability: 3.68%\n",
            "    Output: ' this', probability: 2.67%\n",
            "Input: Ġyou:\n",
            "    Output: ' on', probability: 10.74%\n",
            "    Output: ' all', probability: 8.79%\n",
            "    Output: ' in', probability: 8.00%\n",
            "    Output: ' with', probability: 7.43%\n",
            "    Output: ' back', probability: 5.68%\n",
            "Input: Ġparticipate:\n",
            "    Output: ' in', probability: 76.62%\n",
            "    Output: '.', probability: 5.35%\n",
            "    Output: ' and', probability: 4.71%\n",
            "    Output: '!', probability: 2.80%\n",
            "    Output: ',', probability: 2.03%\n",
            "Input: Ġin:\n",
            "    Output: ' the', probability: 30.19%\n",
            "    Output: ' this', probability: 21.03%\n",
            "    Output: ' our', probability: 16.91%\n",
            "    Output: ' a', probability: 8.07%\n",
            "    Output: ' an', probability: 2.01%\n",
            "Input: Ġour:\n",
            "    Output: ' upcoming', probability: 2.22%\n",
            "    Output: ' new', probability: 1.80%\n",
            "    Output: ' community', probability: 1.61%\n",
            "    Output: ' annual', probability: 1.60%\n",
            "    Output: ' project', probability: 1.51%\n",
            "Input: Ġmodest:\n",
            "    Output: ' fundraising', probability: 3.39%\n",
            "    Output: ',', probability: 3.16%\n",
            "    Output: 'ly', probability: 2.12%\n",
            "    Output: ' and', probability: 2.08%\n",
            "    Output: ' community', probability: 1.38%\n",
            "Input: ĠLL:\n",
            "    Output: 'VM', probability: 10.40%\n",
            "    Output: 'G', probability: 2.89%\n",
            "    Output: 'AP', probability: 2.36%\n",
            "    Output: 'F', probability: 1.90%\n",
            "    Output: 'K', probability: 1.77%\n",
            "Input: M:\n",
            "    Output: ' project', probability: 7.36%\n",
            "    Output: ' program', probability: 2.70%\n",
            "    Output: '-', probability: 1.91%\n",
            "    Output: ' event', probability: 1.57%\n",
            "    Output: ' and', probability: 1.44%\n",
            "Input: Ġworkshop:\n",
            "    Output: '.', probability: 23.24%\n",
            "    Output: ',', probability: 10.71%\n",
            "    Output: ' in', probability: 7.96%\n",
            "    Output: ' on', probability: 7.20%\n",
            "    Output: ' and', probability: 6.62%\n",
            "Input: !:\n",
            "    Output: '\n",
            "', probability: 40.09%\n",
            "    Output: ' We', probability: 6.57%\n",
            "    Output: '<|endoftext|>', probability: 6.24%\n",
            "    Output: ' You', probability: 2.44%\n",
            "    Output: ' Please', probability: 2.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Die Architektur verstehen\n"
      ],
      "metadata": {
        "id": "GCmBb-xMh1Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Laden des vortrainierten Modells und des zugehörigen Tokenizers\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2', output_hidden_states=True)\n",
        "\n",
        "# GPU nutzen wenn verfügar\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device).eval()\n",
        "\n",
        "text = 'Das ist ein Beispieltext für die Demonstration.'\n",
        "\n",
        "tokens = tokenizer.tokenize(text)\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# Verfolgen der Veränderungen in den latenten Zuständen und Bestätigen der konstanten Dimension.\n",
        "# Dazu führen wir die Eingabe durch das gesamte Modell und drucken die Größe der Ausgabe nach jedem Block\n",
        "input_tensor = torch.tensor([input_ids], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Durchführen einer Vorwärtsdurchlaufe durch das Modell\n",
        "    outputs = model(input_tensor)\n",
        "    # Die Ausgabe ist ein Tuple, das die Endausgabe und eine Liste der Zwischenausgaben enthält\n",
        "    final_output, hidden_states = outputs.last_hidden_state, outputs.hidden_states\n",
        "    # Drucken Sie die Größe der Endausgabe und jeder Zwischenausgabe\n",
        "    print(f\"Größe der Endausgabe:\\n\\t{final_output.size()}\\n\")\n",
        "    print(f\"Endausgabe:\\n\\t{final_output}\\n\")\n",
        "    for i, hidden_state in enumerate(hidden_states):\n",
        "        print(f\"Größe der latenten Zustände nach Block {i+1}:\\n\\t{hidden_state.size()}\\n\")\n",
        "        print(f\"Latente Zustände nach Block {i+1}:\\n\\t{hidden_state}\\n\\n\")"
      ],
      "metadata": {
        "id": "4ozdyQmdiNS7",
        "outputId": "c69ef7de-8f2f-47a0-dbf4-90a544c79853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Größe der Endausgabe:\n",
            "\ttorch.Size([1, 1, 16, 768])\n",
            "\n",
            "Endausgabe:\n",
            "\ttensor([[[[-0.1805, -0.1602, -0.2445,  ..., -0.1593,  0.0039, -0.0136],\n",
            "          [-0.3021, -0.3064, -0.4753,  ...,  0.0716, -0.1752,  0.2778],\n",
            "          [-0.6312, -0.3724, -0.7612,  ...,  0.3610, -0.1038,  0.0860],\n",
            "          ...,\n",
            "          [ 0.6071, -0.1206, -0.9526,  ..., -0.4354,  0.0310, -0.5339],\n",
            "          [ 0.0030, -0.4362, -0.2058,  ..., -0.1486, -0.3879, -0.3260],\n",
            "          [ 0.0698, -0.4597, -0.5089,  ..., -0.2768, -0.2152, -0.0472]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Größe der latenten Zustände nach Block 1:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 1:\n",
            "\ttensor([[[ 0.0911, -0.1488,  0.1890,  ..., -0.0553,  0.1373, -0.0367],\n",
            "         [-0.0502, -0.2643, -0.0026,  ...,  0.1705, -0.0574, -0.0334],\n",
            "         [-0.0055, -0.0747,  0.1101,  ...,  0.1342, -0.0187, -0.0468],\n",
            "         ...,\n",
            "         [-0.0501,  0.0583,  0.4026,  ..., -0.0276, -0.2199, -0.0523],\n",
            "         [-0.0544,  0.0188,  0.1011,  ..., -0.0354, -0.1995, -0.0073],\n",
            "         [ 0.0488,  0.0092,  0.1127,  ..., -0.0773,  0.0460,  0.0949]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 2:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 2:\n",
            "\ttensor([[[-8.6780e-01, -1.6939e+00,  8.1993e-01,  ..., -1.4451e+00,\n",
            "          -3.3099e-01,  1.2529e+00],\n",
            "         [-2.3711e+00, -8.9153e-02, -4.1907e-01,  ...,  1.0834e-01,\n",
            "          -2.9978e-02,  6.5335e-01],\n",
            "         [-1.4507e+00, -6.1375e-01, -8.5436e-01,  ...,  6.6315e-01,\n",
            "           1.7717e-04,  8.3909e-01],\n",
            "         ...,\n",
            "         [ 3.0882e+00,  1.7970e-01, -7.9437e-01,  ..., -5.6782e-01,\n",
            "          -1.4546e+00, -9.5938e-01],\n",
            "         [-3.3333e-01, -2.1266e-01,  4.1606e-02,  ...,  4.4749e-01,\n",
            "          -6.7261e-01, -9.5239e-01],\n",
            "         [ 1.1582e+00,  7.7274e-03, -5.7502e-01,  ..., -3.3415e-02,\n",
            "          -1.7869e-01,  1.4895e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 3:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 3:\n",
            "\ttensor([[[-0.9689, -1.9875,  0.9241,  ..., -1.2349,  0.6611,  0.6452],\n",
            "         [-1.6984,  0.1247, -0.4265,  ...,  0.0724,  0.2886,  0.4197],\n",
            "         [-1.0819, -0.7272, -1.4148,  ...,  1.2566,  0.3688,  1.2374],\n",
            "         ...,\n",
            "         [ 3.9381,  0.5510, -1.8351,  ..., -0.4392, -1.3800, -0.3870],\n",
            "         [-0.8068,  0.2660, -0.5286,  ...,  0.3036, -0.7980, -1.0378],\n",
            "         [ 1.6444, -0.4830, -0.9405,  ..., -0.3132,  0.1983,  0.5502]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 4:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 4:\n",
            "\ttensor([[[-0.7086, -2.2935,  0.5609,  ..., -1.2166,  0.8711,  0.5059],\n",
            "         [-1.4906, -0.4384, -0.7218,  ..., -0.5867,  1.3711,  0.4464],\n",
            "         [-1.4419, -0.9732, -2.0607,  ...,  1.2049,  0.1657,  1.0424],\n",
            "         ...,\n",
            "         [ 4.4492,  0.0394, -1.8546,  ..., -1.0592, -1.3634, -0.3636],\n",
            "         [-1.3139,  0.0855, -0.8313,  ...,  0.1707,  0.2583, -0.8920],\n",
            "         [ 1.9362, -0.8187, -1.0610,  ..., -0.1899,  0.2908,  0.7416]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 5:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 5:\n",
            "\ttensor([[[-6.4127e-01, -2.2873e+00,  6.1733e-01,  ..., -1.1654e+00,\n",
            "           8.6678e-01,  3.6842e-01],\n",
            "         [-2.1190e+00, -6.8900e-01, -3.3142e-01,  ...,  7.1661e-01,\n",
            "           3.0818e-01,  4.4499e-01],\n",
            "         [-1.7893e+00, -4.3250e-01, -1.9582e+00,  ...,  1.2738e+00,\n",
            "          -5.9711e-01,  1.3264e+00],\n",
            "         ...,\n",
            "         [ 4.8933e+00, -2.4944e-01, -1.8925e+00,  ..., -1.7886e+00,\n",
            "          -1.7745e+00,  2.0310e-01],\n",
            "         [-9.0010e-01,  7.9144e-01, -1.5351e+00,  ...,  1.4976e-01,\n",
            "          -2.5617e-03, -9.2712e-01],\n",
            "         [ 1.7856e+00, -1.0759e+00, -9.3823e-01,  ..., -2.0255e-01,\n",
            "          -1.8251e-01,  5.9054e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 6:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 6:\n",
            "\ttensor([[[-0.8285, -2.3596,  0.5320,  ..., -1.3341,  0.7238,  0.3699],\n",
            "         [-1.1233, -1.4394, -0.5654,  ...,  0.6341,  0.1042,  0.2412],\n",
            "         [-1.7185, -0.3660, -1.9395,  ...,  1.1227, -1.4451,  1.7288],\n",
            "         ...,\n",
            "         [ 5.5515,  0.2181, -2.3139,  ..., -2.1099, -2.3544,  0.3981],\n",
            "         [-0.9635,  1.3844, -2.1596,  ..., -0.8610, -0.4416, -0.6148],\n",
            "         [ 1.8560, -1.6745, -1.2009,  ..., -0.4101, -0.5796,  0.3958]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 7:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 7:\n",
            "\ttensor([[[-0.8537, -2.4543,  0.5723,  ..., -1.4362,  0.6389,  0.3736],\n",
            "         [-1.6854, -2.0881, -0.8161,  ..., -0.4309, -1.3993,  1.0281],\n",
            "         [-1.8814,  0.1707, -2.2969,  ...,  0.3322, -2.0702,  1.4498],\n",
            "         ...,\n",
            "         [ 5.7863,  0.1437, -2.4282,  ..., -2.7702, -1.8702, -0.2987],\n",
            "         [-1.0866,  1.6824, -2.5665,  ..., -0.7798,  0.2325, -0.4299],\n",
            "         [ 1.6239, -1.6974, -1.2744,  ..., -0.0482, -0.0436,  0.8880]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 8:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 8:\n",
            "\ttensor([[[-0.9446, -2.4644,  0.6284,  ..., -1.5110,  0.6196,  0.3989],\n",
            "         [-1.7603, -1.7282, -1.5534,  ...,  0.7757, -2.5871,  1.3991],\n",
            "         [-1.6237,  0.1183, -2.4290,  ...,  0.2173, -2.0877,  2.2281],\n",
            "         ...,\n",
            "         [ 6.6249,  0.5627, -3.2050,  ..., -2.7895, -2.0410, -0.5208],\n",
            "         [-1.5364,  0.4954, -3.0861,  ..., -0.3838, -0.1180, -0.0535],\n",
            "         [ 0.5571, -3.3804, -2.6739,  ...,  0.4513,  0.5364,  1.4572]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 9:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 9:\n",
            "\ttensor([[[-0.9980, -2.3843,  0.5015,  ..., -1.4533,  0.5272,  0.2545],\n",
            "         [-1.9110, -1.0399, -0.8994,  ...,  1.6302, -2.6736,  2.1934],\n",
            "         [-1.8689, -0.3377, -2.4041,  ...,  1.0703, -2.3965,  2.0800],\n",
            "         ...,\n",
            "         [ 7.4649,  0.7959, -1.3910,  ..., -2.2043, -0.7415, -1.6840],\n",
            "         [ 0.2641,  0.2894, -2.1732,  ...,  1.1806,  0.1958, -1.1574],\n",
            "         [ 1.6692, -3.3584, -2.8830,  ...,  0.1992,  0.8593,  1.8930]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 10:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 10:\n",
            "\ttensor([[[-0.9850, -2.3361,  0.4464,  ..., -1.3621,  0.4881,  0.1393],\n",
            "         [-0.9442, -1.0247, -2.2042,  ...,  1.0314, -1.3090,  2.7587],\n",
            "         [-3.2372, -1.3802, -2.5874,  ...,  2.0381, -1.4779,  1.9904],\n",
            "         ...,\n",
            "         [ 7.6763,  3.1915, -3.4594,  ..., -3.2668,  1.6244, -3.6151],\n",
            "         [ 0.5654,  1.2110, -3.2167,  ...,  0.2370,  1.0944, -2.7497],\n",
            "         [ 1.8687, -3.0614, -4.6514,  ...,  0.8904,  2.6225,  1.1862]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 11:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 11:\n",
            "\ttensor([[[-1.0544, -2.2440,  0.1360,  ..., -1.3183,  0.6060, -0.1071],\n",
            "         [-2.1870, -1.6601, -3.0674,  ...,  0.8746, -1.1006,  2.6336],\n",
            "         [-4.8073, -2.8698, -4.2580,  ...,  3.7331, -0.9701,  1.4990],\n",
            "         ...,\n",
            "         [ 5.7784,  1.6183, -6.0714,  ..., -4.6667,  2.0194, -6.0991],\n",
            "         [-2.2743,  1.4888, -3.1535,  ..., -1.7445,  0.5930, -5.7910],\n",
            "         [-0.1192, -2.3250, -6.6739,  ..., -2.7141,  1.6907, -0.8877]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 12:\n",
            "\ttorch.Size([1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 12:\n",
            "\ttensor([[[-1.1886e+00, -2.1410e+00, -1.6110e-01,  ..., -1.3091e+00,\n",
            "           8.4109e-01, -3.4720e-01],\n",
            "         [-1.9333e+00, -3.0579e+00, -3.1960e+00,  ...,  9.9296e-01,\n",
            "          -6.6876e-01,  2.4818e+00],\n",
            "         [-6.3601e+00, -4.4979e+00, -6.2238e+00,  ...,  4.8597e+00,\n",
            "          -6.3024e-01,  1.1468e+00],\n",
            "         ...,\n",
            "         [ 5.2111e+00,  1.6977e+00, -5.5917e+00,  ..., -3.9830e+00,\n",
            "           2.4351e+00, -6.2948e+00],\n",
            "         [-8.8515e-01, -2.3185e-03, -1.1801e+00,  ..., -1.6234e+00,\n",
            "          -3.0710e+00, -6.2010e+00],\n",
            "         [ 4.0168e-01, -1.0885e+00, -5.5801e+00,  ..., -2.0260e+00,\n",
            "          -1.7729e+00, -4.0947e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "Größe der latenten Zustände nach Block 13:\n",
            "\ttorch.Size([1, 1, 16, 768])\n",
            "\n",
            "Latente Zustände nach Block 13:\n",
            "\ttensor([[[[-0.1805, -0.1602, -0.2445,  ..., -0.1593,  0.0039, -0.0136],\n",
            "          [-0.3021, -0.3064, -0.4753,  ...,  0.0716, -0.1752,  0.2778],\n",
            "          [-0.6312, -0.3724, -0.7612,  ...,  0.3610, -0.1038,  0.0860],\n",
            "          ...,\n",
            "          [ 0.6071, -0.1206, -0.9526,  ..., -0.4354,  0.0310, -0.5339],\n",
            "          [ 0.0030, -0.4362, -0.2058,  ..., -0.1486, -0.3879, -0.3260],\n",
            "          [ 0.0698, -0.4597, -0.5089,  ..., -0.2768, -0.2152, -0.0472]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}